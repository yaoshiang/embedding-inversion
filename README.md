# embedding-inversion

https://www.microsoft.com/en-us/research/publication/text-embeddings-by-weakly-supervised-contrastive-pre-training/

## python src/bert_priors.py

This script runs BERT with masks to probe it's priors. 

## python src/attack_e5.py

This script runs the deep dream on BERT. Key hyperparameters are spread 

## python src/distilbert.py

This script outputs multiple intermediate datastructures from DistilBERT and it's tokenizers.

